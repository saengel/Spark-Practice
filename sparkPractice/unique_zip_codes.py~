# Set up the spark context
import pyspark

sc = pyspark.SparkContext()
sc.setLogLevel("ERROR")

# Bring in the data into the program
textData = sc.textFile("NYfec.gz")

# QUESTION
# - number of unique ZIP codes
# Map out the zip codes
# Distinct them
# Count them

# Defining a function to pass into map
# to extract just the zip codes
def getZip(x):
    fields = split("|")
    possible = fields[10][:5] # Just the first five char
    zipcode = int(possible)
    return zipcode

# Map to zip and distinctify
a = textData.map(getZip).distinct()

# Now count them
c = a.count()

print("Total number of zip codes is = " + c)
